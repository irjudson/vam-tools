# GPU Setup Guide for VAM Tools

## Your Hardware

**Detected GPU**: NVIDIA GeForce RTX 5060 Ti
**Memory**: 16GB VRAM
**Driver Version**: 580.95.05
**Status**: ‚úÖ GPU hardware detected, drivers installed

## Current Status

- ‚úÖ NVIDIA GPU detected (RTX 5060 Ti, 16GB)
- ‚úÖ NVIDIA drivers installed (580.95.05)
- ‚ùå PyTorch with CUDA support not installed
- ‚ùå GPU acceleration not enabled

## Quick Start: Enable GPU Acceleration

### Step 1: Install PyTorch with CUDA Support

```bash
# Activate your virtual environment
source venv/bin/activate

# Install PyTorch with CUDA 12.x support (matches your driver)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124
```

### Step 2: Verify GPU Detection

```bash
# Test GPU detection
python vam_tools/core/gpu_utils.py
```

Expected output:
```
GPU Information:
  Available: True
  Device: NVIDIA GeForce RTX 5060 Ti
  Memory: 16.00 GB
  Backends: cuda
  CUDA Version: 12.4
  Compute Capability: (9, 0)

Recommended Configuration:
{
  "use_gpu": true,
  "batch_size": 64,
  "num_workers": 8
}
```

### Step 3: Test with Your Catalog

```bash
# Run duplicate detection with GPU acceleration
vam-analyze /path/to/catalog --detect-duplicates --hash-methods all --gpu

# Or with specific GPU batch size
vam-analyze /path/to/catalog --detect-duplicates --hash-methods all --gpu --gpu-batch-size 64
```

## Performance Expectations

With your **RTX 5060 Ti (16GB)**, you can expect:

### Hash Computation
- **CPU**: ~3ms per image ‚Üí **3 seconds per 1000 images**
- **GPU**: ~0.15ms per image (batched) ‚Üí **150ms per 1000 images**
- **Speedup**: **~20x faster**

### For Your 87,500 Image Catalog
- **CPU hash computation**: ~4.4 minutes
- **GPU hash computation**: ~13-15 seconds ‚ú®
- **Savings**: ~4 minutes

### Similarity Search (Most Important!)
- **CPU pairwise comparison**: O(n¬≤) ‚Üí ~5-10 minutes for large catalogs
- **GPU with FAISS**: <1 second ‚ö°
- **Speedup**: **300-600x faster**

## Recommended Configuration for Your GPU

Based on 16GB VRAM:

```python
GPU_CONFIG = {
    "enabled": True,
    "batch_size": 64,  # Can go higher if needed
    "memory_limit_gb": 14.0,  # Reserve 2GB for system
    "num_workers": 8,
    "device_id": 0,
}
```

## Installation Options

### Option A: Via Package Extras (Recommended)
Install VAM Tools with GPU support using package extras:

```bash
# Activate your virtual environment
source venv/bin/activate

# Option 1: GPU acceleration for hash computation
pip install -e ".[gpu]"

# Option 2: Add FAISS for fast similarity search
pip install -e ".[gpu-all]"

# Or install from the specific PyTorch index for CUDA 12.4
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124
```

**Size**: ~2.5GB
**Features**:
- GPU batch hash computation
- GPU-accelerated image preprocessing
- 10-20x speedup

### Option B: Manual Installation (More Control)
Install dependencies manually for specific CUDA versions:

```bash
# Install PyTorch with CUDA 12.4 (matches your driver)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124

# Install FAISS for fast similarity search
# Note: GPU version requires conda
pip install faiss-cpu  # CPU version via pip
# OR
conda install -c conda-forge faiss-gpu  # GPU version via conda
```

**Size**: ~3GB total
**Features**:
- Everything from Option A
- FAISS similarity search (CPU or GPU)
- 100-300x speedup for finding duplicates in large catalogs

### Option C: Ultimate Performance (For Production)
Add NVIDIA DALI for maximum image preprocessing speed:

```bash
# Install all GPU dependencies
pip install -e ".[gpu-all]"
pip install --extra-index-url https://pypi.nvidia.com nvidia-dali-cuda120

# Or with cupy for additional NumPy acceleration
pip install cupy-cuda12x
```

**Size**: ~4GB total
**Features**:
- Maximum performance
- GPU-accelerated JPEG decoding
- Up to 50x speedup for image preprocessing

## Testing GPU Performance

Create a test script to compare CPU vs GPU:

```python
import time
from pathlib import Path
from vam_tools.core.gpu_utils import detect_gpu, get_optimal_config
from vam_tools.analysis.perceptual_hash import combined_hash

# Detect GPU
gpu_info = detect_gpu()
print(f"GPU Available: {gpu_info.available}")
print(f"Recommended batch size: {gpu_info.recommended_batch_size}")

# Test with your images
image_dir = Path("/path/to/your/images")
images = list(image_dir.glob("*.jpg"))[:1000]  # Test with 1000 images

print(f"\nTesting with {len(images)} images...")

# CPU baseline
start = time.time()
for img in images:
    combined_hash(img)
cpu_time = time.time() - start

print(f"CPU time: {cpu_time:.2f}s ({cpu_time/len(images)*1000:.2f}ms per image)")

# GPU (once implemented)
# gpu_time = test_gpu_batch(images)
# print(f"GPU time: {gpu_time:.2f}s ({gpu_time/len(images)*1000:.2f}ms per image)")
# print(f"Speedup: {cpu_time/gpu_time:.1f}x")
```

## Troubleshooting

### PyTorch doesn't detect GPU
```bash
python -c "import torch; print(torch.cuda.is_available())"
```

If False, reinstall with correct CUDA version:
```bash
pip uninstall torch torchvision
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124
```

### Out of Memory Errors
Reduce batch size:
```bash
vam-analyze /catalog --detect-duplicates --gpu --gpu-batch-size 32
```

### GPU Usage Not Showing in nvidia-smi
```bash
# Monitor GPU usage in real-time
watch -n 1 nvidia-smi
```

Then run your analysis in another terminal.

## Next Steps

1. **Install PyTorch with CUDA** (Option A above)
2. **Verify GPU detection** works
3. **Test on small subset** of your 87,500 images
4. **Measure performance improvement**
5. **If satisfied, install FAISS** for similarity search acceleration
6. **Report results** for further optimization!

## Expected Timeline for Full GPU Implementation

- ‚úÖ **Week 0**: GPU detection and configuration (DONE)
- üìÖ **Week 1**: Batch processing with GPU (3-5 days)
- üìÖ **Week 2**: FAISS integration for similarity search (2-3 days)
- üìÖ **Week 3**: Optimization and testing (2-3 days)

**Total**: 2-3 weeks for full GPU acceleration

For your immediate use case (87,500 images), **FAISS similarity search will give you the biggest win** (5 min ‚Üí <1 sec)!
