# VAM Tools - Development Notes

This document contains historical information about the project's evolution, completed work, and implementation notes.

## Table of Contents

- [Project History](#project-history)
- [Reimplementation Summary](#reimplementation-summary)
- [Project Rename](#project-rename)
- [Duplicate Detection Implementation](#duplicate-detection-implementation)
- [Code Reduction Plan](#code-reduction-plan)

---

## Project History

### Origins

VAM Tools originated as "lightroom-tools", a collection of scripts for managing Lightroom photo catalogs. The project evolved into a comprehensive Visual Asset Management system focused on organizing large photo/video libraries.

### Evolution Timeline

1. **V0.1**: Initial scripts for Lightroom catalog manipulation
2. **V0.2**: Rewritten as proper Python package with CLI
3. **V1.0**: Complete reimplementation with tests and modern tooling
4. **V2.0**: Catalog-based architecture with web UI (current)

---

## Reimplementation Summary

### Overview

Successfully reimplemented VAM Tools from scratch as a clean, professional Python package with full test coverage, type hints, comprehensive documentation, and modern CLI interfaces.

### Project Statistics

- **Total Python files**: 18 (11 source + 7 test)
- **Lines of code**: ~3,000
- **Test coverage**: 84% overall (213 tests passing)
- **Type hints**: Full type annotations throughout
- **Documentation**: Complete README with examples

### What Was Built

**Core Modules** (`vam_tools/core/`):
1. **image_utils.py** (~150 LOC): Image detection, validation, metadata
2. **date_extraction.py** (~280 LOC): EXIF, filename, directory date extraction
3. **duplicate_detection.py** (~300 LOC): MD5, dHash, aHash for duplicates
4. **catalog_reorganization.py** (~280 LOC): Organization strategies

**Analysis Modules** (`vam_tools/analysis/`):
1. **scanner.py**: Multi-core parallel file processing
2. **metadata.py** (~500 LOC): Comprehensive EXIF extraction via ExifTool
3. **perceptual_hash.py** (~220 LOC): dHash and aHash implementations
4. **quality_scorer.py** (~300 LOC): Image quality assessment
5. **duplicate_detector.py** (~420 LOC): Full duplicate detection workflow

**Web Modules** (`vam_tools/web/`):
1. **api.py** (~500 LOC): FastAPI REST endpoints
2. **static/index.html**: Vue 3 SPA for catalog browsing

**CLI Modules** (`vam_tools/cli/`):
1. **main.py** (~300 LOC): Interactive menu system
2. **analyze.py**: Analysis CLI with progress tracking
3. **web.py**: Web server launcher

### Key Improvements Over Original

**Architecture:**
- ✅ Separation of concerns (core logic vs CLI)
- ✅ Clean imports (no sys.argv manipulation)
- ✅ Proper packaging (correct entry points)
- ✅ Reusable core (can be used as library)

**Code Quality:**
- ✅ Type hints throughout
- ✅ Comprehensive docstrings
- ✅ Black formatting, isort imports
- ✅ Flake8 linting
- ✅ No code smells

**Testing:**
- ✅ 213 tests (vs. zero before)
- ✅ 84% coverage
- ✅ Reusable fixtures
- ✅ Unit, integration, and edge case tests
- ✅ CI/CD pipeline

**User Experience:**
- ✅ Rich terminal UI (progress bars, tables)
- ✅ Better feedback (clear messages, warnings)
- ✅ Dry-run mode
- ✅ Multiple entry points
- ✅ Web interface for browsing

---

## Project Rename

**Date**: October 25, 2025
**Status**: ✅ COMPLETE

### What Changed

**Package Name:**
- Old: `lightroom-tools` / `lightroom_tools`
- New: `vam-tools` / `vam_tools`
- Rationale: VAM (Visual Asset Management) better reflects broader mission

**Version:**
- Old: v0.2.0 (v1 implementation)
- New: v2.0.0 (v2 implementation)

**CLI Commands:**
- Old: `lightroom-tools`, `lr-dates`, `lr-duplicates`, `lr-catalog`
- New: `vam-analyze`, `vam-web`

**Directory Structure:**
```
lightroom-tools/         →  vam-tools/
├── lightroom_tools/     →  vam_tools/
├── .old_code/           →  .old_lightroom_code/
├── tests/               (imports updated)
└── *.md                 (all updated)
```

### Project Focus After Rename

**Before**: "Tools for Lightroom catalogs"
**After**: "Visual Asset Management - organize photo/video libraries with one correct copy of each asset"

**Current Priority:**
- Get duplicates working (perceptual hashing, quality scoring)
- Get organization execution working (move files to YYYY-MM structure)
- Get import system working (ongoing maintenance)

**Deferred:**
- AI features (burst detection, quality scoring)
- Advanced curation
- Auto-tagging

---

## Duplicate Detection Implementation

**Date**: Completed October 2025
**Status**: ✅ COMPLETE

### What's Implemented

1. **Perceptual Hashing**: dHash and aHash for finding similar images
2. **Quality Scoring**: Rank duplicates by format, resolution, size, metadata
3. **Duplicate Detector**: Complete workflow from scanning to selection
4. **Enhanced Metadata**: Camera info, GPS, settings for quality scoring
5. **CLI Integration**: `--detect-duplicates` flag for vam-analyze
6. **Catalog Storage**: Save/load duplicate groups

### Testing

- **55 new tests** for perceptual hashing and quality scoring
- **91% coverage** on perceptual_hash.py
- **89% coverage** on quality_scorer.py
- **All 213 tests passing**

### Files Created

**New Modules (3):**
- `vam_tools/analysis/perceptual_hash.py` (218 lines)
- `vam_tools/analysis/quality_scorer.py` (296 lines)
- `vam_tools/analysis/duplicate_detector.py` (417 lines)

**Test Files (2):**
- `tests/analysis/test_perceptual_hash.py` (298 lines)
- `tests/analysis/test_quality_scorer.py` (401 lines)

### Usage

```bash
# Enable duplicate detection
vam-analyze /path/to/catalog \
  --source /path/to/photos \
  --detect-duplicates

# Adjust sensitivity
vam-analyze /path/to/catalog \
  --source /path/to/photos \
  --detect-duplicates \
  --similarity-threshold 3
```

### Algorithm Details

**Perceptual Hashing:**
- **dHash** (Difference Hash): Compares pixel gradients
- **aHash** (Average Hash): Compares pixel averages
- Combined approach for better accuracy
- Hamming distance for similarity measurement

**Quality Scoring (0-100):**
1. **Format quality** (40%): RAW > JPEG > others
2. **Resolution** (30%): Higher resolution preferred
3. **File size** (20%): Larger (non-compressed) preferred
4. **Metadata completeness** (10%): More EXIF data preferred

**Selection Strategy:**
- Automatically selects highest quality image as primary
- Groups all similar images (above threshold)
- Marks redundant copies for potential removal
- Flags low-confidence groups for manual review

---

## Code Reduction Plan

**Note**: This plan was created but NOT executed. The codebase has been significantly improved through the reimplementation, but this specific refactoring plan was deferred.

### Original Goal

Reduce codebase from **4,606 lines** to **~3,685 lines** (20% reduction = 921 lines) through:
1. Eliminating V1/V2 duplication
2. Using Pydantic for serialization
3. Consolidating CLI patterns
4. API pattern consolidation

### Proposed Phases

**Phase 1: Shared Utilities Module** (~300 lines saved)
- Create `vam_tools/shared/media_utils.py`
- Consolidate file type detection, checksums, date patterns
- Eliminate duplication between V1 and V2 modules
- Status: ✅ COMPLETED (implemented during reimplementation)

**Phase 2: Pydantic for Serialization** (~190 lines saved)
- Convert types to Pydantic models
- Replace manual serialization methods
- Auto-validation and JSON schema generation
- Status: ✅ COMPLETED (Pydantic v2 used throughout)

**Phase 3: CLI Base Framework** (~200 lines saved)
- Create `vam_tools/cli/base.py`
- Composable decorators for common options
- Standardized output and progress bars
- Status: ❌ NOT IMPLEMENTED (kept simple CLIs)

**Phase 4: API Pattern Consolidation** (~100 lines saved)
- Use Pydantic auto-serialization in API
- Generic response helpers
- Status: ❌ NOT IMPLEMENTED (API is clean as-is)

**Phase 5: Type Simplification** (~50 lines saved)
- Consolidate similar enums
- Use Literals for simple choices
- Status: ✅ PARTIALLY DONE (types are clean)

### Why Not Fully Executed?

The reimplementation achieved code quality goals without requiring all refactoring steps:
- Modern architecture eliminated most duplication naturally
- Pydantic was adopted from the start
- CLI code is already clean and maintainable
- Current test coverage (84%) is excellent
- Code is readable and well-documented

The plan remains valid for future optimization but is not critical given current code quality.

---

## Implementation Lessons Learned

### What Worked Well

1. **Test-First Development**: Writing tests before/during implementation caught bugs early
2. **Type Hints**: Made refactoring safer and caught type errors at development time
3. **Checkpoint System**: Enabled safe interruption of long-running scans
4. **Pydantic Models**: Auto-validation prevented many bugs in catalog serialization
5. **Rich CLI**: User feedback was excellent, made tools feel professional
6. **FastAPI**: Web API was trivial to implement with automatic OpenAPI docs

### Challenges Overcome

1. **ExifTool Integration**: Needed context manager for proper subprocess management
2. **HEIC Support**: Required pillow-heif integration for modern iPhone photos
3. **File Locking**: Implemented signal-based timeouts to prevent deadlocks
4. **Perceptual Hashing**: Tuned threshold values through experimentation
5. **Multi-core Scaling**: Required careful chunk size calculation for efficiency

### Design Decisions

**Why JSON for Catalog?**
- Human-readable (can inspect with `jq` or text editor)
- Version controllable (can use git for catalog history)
- Simple backup/restore (just copy file)
- No database dependency (easier deployment)
- Fast enough for 100k+ images in memory

**Why ExifTool over Pillow?**
- More comprehensive metadata extraction
- Better support for video files
- Handles more image formats
- Industry-standard tool

**Why Not Async?**
- I/O bound on disk reads (async doesn't help)
- Multiprocessing provides true parallelism
- Simpler code (no async complexity)
- Better CPU utilization

**Why Vue CDN vs Build?**
- Zero build step (edit HTML and refresh)
- Simpler deployment (single HTML file)
- Good enough for local-only app
- Can upgrade to build later if needed

### Performance Optimizations

1. **Chunked File Reading**: 8KB chunks for checksums (memory efficient)
2. **Multiprocessing**: Linear scaling up to CPU count
3. **Checkpoint System**: Save every 100 files (resume capability)
4. **Path Indexing**: O(1) lookup by checksum in catalog
5. **Lazy Loading**: Web UI loads images in batches of 50

### Security Considerations

1. **File Locking**: fcntl.flock prevents concurrent writes
2. **Path Validation**: Prevent path traversal attacks
3. **Extension Whitelist**: Only process known image/video types
4. **No Authentication**: Designed for local use only (localhost by default)
5. **Read-Only Web UI**: Can't modify files or catalog

---

## Future Ideas

### Short Term (Next 3 Months)

1. **Organization Execution**: Implement file move/copy to YYYY-MM structure
2. **Plan Review UI**: Web interface for reviewing/approving organization plan
3. **Import System**: Add new photos to existing catalog efficiently
4. **Batch Operations**: Mark multiple files for action

### Medium Term (3-6 Months)

1. **Burst Detection**: Group sequential images, auto-select best
2. **Advanced Filters**: Search by camera, lens, location, date range
3. **Export Capabilities**: Export subsets of catalog
4. **Conflict Resolution**: UI for resolving date conflicts

### Long Term (6+ Months)

1. **AI Features**: Scene detection, face recognition, quality assessment
2. **Auto-Tagging**: Location, time, content, technical, quality tags
3. **Smart Collections**: Dynamic collections based on rules
4. **Cloud Integration**: Backup to cloud storage
5. **Mobile App**: View catalog on mobile devices

### Technical Improvements

1. **SQLite Backend**: For catalogs >500k images
2. **Thumbnail Cache**: Speed up web UI loading
3. **Incremental Hashing**: Only hash new/changed files
4. **Plugin System**: Allow custom analyzers/organizers
5. **Distributed Processing**: Support remote workers

---

## Metrics and Progress

### Current Statistics

**Codebase:**
- Total lines: ~7,500 (including tests and docs)
- Production code: ~4,000
- Test code: ~2,500
- Documentation: ~1,000

**Test Coverage:**
- Overall: 84%
- Core modules: 85%+
- Analysis modules: 81-91%
- CLI modules: 79%+
- Web modules: Not measured (frontend)

**Performance:**
- ~1-5 images/second (depends on file size, disk speed)
- Linear scaling up to CPU count
- Tested with 100,000+ images
- ~500 bytes per image in memory

### Quality Gates

All commits must pass:
- ✅ Black formatting
- ✅ isort import sorting
- ✅ flake8 linting
- ✅ pytest (213 tests)
- ✅ mypy type checking (31 errors remaining, non-blocking)

### Known Issues

1. **31 mypy errors remaining**: Mostly Optional handling and str/Path conversions (non-critical)
2. **No Windows testing**: CI runs on Linux and macOS only
3. **No authentication**: Web UI is localhost-only (by design)
4. **Memory usage**: Entire catalog loaded in memory (fine for <500k images)
5. **No progress persistence**: Web UI doesn't show ongoing analysis progress

---

## Contributing Notes

### Development Setup

```bash
# Clone and setup
cd vam-tools
python -m venv venv
source venv/bin/activate
pip install -e ".[dev]"

# Configure git hooks
git config core.hooksPath .githooks
```

### Before Committing

```bash
# Format code
black vam_tools/ tests/
isort vam_tools/ tests/

# Check linting
flake8 vam_tools/ tests/

# Run tests
pytest

# Pre-push hook runs automatically
git push  # Runs all checks
```

### Code Style

- **Black** for formatting (line length: 88)
- **isort** for import sorting (Black-compatible)
- **flake8** for linting
- **Type hints** on all public functions
- **Docstrings** on all public APIs (Google style)

### Testing Philosophy

1. **Write tests first** (or alongside implementation)
2. **Test behavior, not implementation**
3. **Use fixtures** for common test data
4. **Aim for 80%+ coverage**
5. **Include edge cases**

---

## Acknowledgments

This project was built using modern Python development practices and would not have been possible without:

- **Python Community**: For excellent libraries and tools
- **ExifTool**: Comprehensive metadata extraction
- **Pillow**: Image processing
- **FastAPI**: Modern web framework
- **Vue.js**: Reactive frontend framework
- **Rich**: Beautiful terminal output
- **pytest**: Excellent testing framework
- **Pydantic**: Type-safe data validation

---

## Changelog

### v2.0.0 (Current)
- Complete reimplementation with catalog-based architecture
- Web UI for catalog browsing
- Perceptual duplicate detection
- Multi-core parallel processing
- Checkpoint system for long scans
- 213 tests, 84% coverage

### v1.0.0
- Initial reimplementation as proper Python package
- CLI tools for dates, duplicates, catalog
- Test suite and CI/CD
- Type hints and documentation

### v0.2.0
- Basic Lightroom catalog tools
- Simple CLI interface
- No tests

### v0.1.0
- Initial scripts
- Ad-hoc functionality

---

**Last Updated**: 2025-10-26
